Model,Dataset,Length,Latency_sec,Memory_MB,Energy_J,Avg_Power_W
meta-llama/Llama-2-7b-hf,alpaca,short,8.681007385253906,13780.65664,595.11,66.1
meta-llama/Llama-2-7b-hf,alpaca,short,8.359586954116821,13808.9728,650.71,72.3
meta-llama/Llama-2-7b-hf,alpaca,medium,35.734944581985474,14596.790784,2591.4,72.0
meta-llama/Llama-2-7b-hf,alpaca,medium,35.798370122909546,14624.493568,2593.23,72.0
meta-llama/Llama-2-7b-hf,alpaca,long,78.52138113975525,15687.358976,5604.98,71.9
meta-llama/Llama-2-7b-hf,alpaca,long,78.88101029396057,15715.065856,5597.5,71.8
meta-llama/Llama-2-7b-hf,gsm8k,short,8.419505596160889,13841.51296,639.4,71.0
meta-llama/Llama-2-7b-hf,gsm8k,short,8.430871725082397,13847.776256,651.14,72.3
meta-llama/Llama-2-7b-hf,gsm8k,medium,36.402657985687256,14713.976832,2587.85,71.9
meta-llama/Llama-2-7b-hf,gsm8k,medium,37.05046105384827,14850.310656,2663.77,72.0
meta-llama/Llama-2-7b-hf,gsm8k,long,17.447124242782593,14168.745984,1291.77,71.8
meta-llama/Llama-2-7b-hf,gsm8k,long,17.80138087272644,14285.39648,1296.17,72.0
