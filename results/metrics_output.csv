Model,Quantization,Context_Window,Dataset,Batch_Number,Latency_sec,Memory_MB,Energy_J,Power_W,Input_Tokens,Output_Tokens,Energy_per_InputToken,Energy_per_OutputToken,Carbon_gCO2eq
meta-llama/Llama-2-7b-hf,fp16,2048,alpaca,2,74.28960000000001,14850.3142,5331.4400000000005,71.7656,1024,4096,5.2065,1.3016,0.217565
